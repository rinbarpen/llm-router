# LLM Router 配置文件
# 配置 Provider、模型和 API Key 设置

######################
# Server Settings    #
######################
# 服务器配置（可选，也可以通过环境变量 LLM_ROUTER_HOST 和 LLM_ROUTER_PORT 设置）
[server]
host = "0.0.0.0"  # 服务绑定的主机地址
port = 18000       # 服务绑定的端口

######################
# Frontend Settings #
######################
# 前端配置（可选，也可以通过环境变量 VITE_PORT、VITE_API_URL、VITE_API_BASE_URL 设置）
[frontend]
port = 4022                    # 前端开发服务器端口
api_url = "http://localhost:18000"  # 后端API服务器地址（开发环境代理用）
api_base_url = "/api"          # 生产环境API基础路径

######################
# Provider Settings  #
######################

[[providers]]
name = "openai"
type = "openai"
# Environment variable that stores your OpenAI API key
api_key_env = "OPENAI_API_KEY"
base_url = "https://api.openai.com"

[[providers]]
name = "gemini"
type = "gemini"
api_key_env = "GEMINI_API_KEY"

[[providers]]
name = "claude"
type = "claude"
api_key_env = "ANTHROPIC_API_KEY"

[[providers]]
name = "openrouter"
type = "openrouter"
api_key_env = "OPENROUTER_API_KEY"

[[providers]]
name = "glm"
type = "glm"
api_key_env = "GLM_API_KEY"
base_url = "https://open.bigmodel.cn/api/coding/paas/v4"
[providers.settings]
endpoint = "/chat/completions"

[[providers]]
name = "kimi"
type = "kimi"
api_key_env = "KIMI_API_KEY"

[[providers]]
name = "qwen"
type = "qwen"
api_key_env = "DASHSCOPE_API_KEY"

[[providers]]
name = "ollama"
type = "ollama"
# Ollama 不需要 API Key，默认连接到 http://127.0.0.1:11434
# 如果需要连接到其他地址，可以设置 base_url
# base_url = "http://127.0.0.1:11434"

[[providers]]
name = "vercel"
type = "openai"
# Vercel 部署的 OpenAI 兼容服务
# 请将 YOUR_VERCEL_URL 替换为实际的 Vercel 部署地址
base_url = "https://YOUR_VERCEL_URL.vercel.app"
# 如果 Vercel 服务需要 API Key，请设置 api_key_env
# api_key_env = "VERCEL_API_KEY"
# 或者直接设置（不推荐）
# api_key = "your-vercel-api-key"


###################
# OpenAI Models   #
###################

[[models]]
name = "gpt-5.1"
provider = "openai"
display_name = "GPT-5.1"
tags = ["chat", "general", "image", "audio", "high-quality"]
[models.rate_limit]
max_requests = 50
per_seconds = 60
[models.config]
context_window = "272k"
supports_vision = true
supports_tools = true
languages = ["en"]

[[models]]
name = "gpt-5-pro"
provider = "openai"
display_name = "GPT-5 Pro"
tags = ["chat", "general", "image", "audio", "reasoning", "high-quality"]
[models.rate_limit]
max_requests = 60
per_seconds = 60
[models.config]
context_window = "272k"
supports_vision = true
supports_tools = true
languages = ["en"]


####################
# Claude Models    #
####################

[[models]]
name = "claude-4.5-sonnet"
provider = "claude"
display_name = "Claude 4.5 Sonnet"
tags = ["chat", "writing", "analysis", "reasoning", "high-quality"]
[models.config]
context_window = "200k"
supports_vision = true
supports_tools = true
languages = ["en"]

[[models]]
name = "claude-4.5-haiku"
provider = "claude"
display_name = "Claude 4.5 Haiku"
tags = ["chat", "writing", "fast", "general"]
[models.config]
context_window = "200k"
supports_vision = true
supports_tools = true
languages = ["en"]


####################
# Gemini Models    #
####################

[[models]]
name = "gemini-2.5-flash"
provider = "gemini"
display_name = "Gemini 2.5 Flash"
tags = ["chat", "general", "audio", "image", "video", "reasoning", "fast"]
[models.config]
context_window = "1M"
supports_vision = true
supports_tools = true
languages = ["en"]

[[models]]
name = "gemini-2.5-pro"
provider = "gemini"
display_name = "Gemini 2.5 Pro"
tags = ["chat", "general", "image", "audio", "video", "long-context", "high-quality"]
[models.config]
context_window = "1M"
supports_vision = true
supports_tools = true
languages = ["en"]

[[models]]
name = "gemini-3.0-pro"
provider = "gemini"
display_name = "Gemini 3.0 Pro"
tags = ["chat", "general", "image", "audio", "video", "long-context", "high-quality"]
[models.config]
context_window = "1M"
supports_vision = true
supports_tools = true
languages = ["en"]


###################
# GLM Models      #
###################

[[models]]
name = "glm-4-plus"
provider = "glm"
remote_identifier = "GLM-4-Plus"
display_name = "GLM-4 Plus"
tags = ["chat", "chinese", "general", "high-quality"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4-air"
provider = "glm"
remote_identifier = "GLM-4-Air"
display_name = "GLM-4 Air"
tags = ["chat", "chinese", "general", "fast"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4-airx"
provider = "glm"
remote_identifier = "GLM-4-AirX"
display_name = "GLM-4 AirX"
tags = ["chat", "chinese", "general", "fast"]
[models.config]
context_window = "8k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4-flashx"
provider = "glm"
remote_identifier = "GLM-4-FlashX-250414"
display_name = "GLM-4 FlashX"
tags = ["chat", "chinese", "general", "fast", "cheap"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4-long"
provider = "glm"
remote_identifier = "GLM-4-Long"
display_name = "GLM-4 Long"
tags = ["chat", "chinese", "general", "long-context"]
[models.config]
context_window = "1M"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4-assistant"
provider = "glm"
remote_identifier = "GLM-4-Assistant"
display_name = "GLM-4 Assistant"
tags = ["chat", "chinese", "general", "agentic", "function-call"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.7"
provider = "glm"
remote_identifier = "GLM-4.7"
display_name = "GLM-4.7"
tags = ["chat", "chinese", "general", "high-quality"]
[models.config]
context_window = "200k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.6"
provider = "glm"
remote_identifier = "GLM-4.6"
display_name = "GLM-4.6"
tags = ["chat", "chinese", "general", "high-quality"]
[models.config]
context_window = "200k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.6-plus"
provider = "glm"
remote_identifier = "GLM-4.6-Plus"
display_name = "GLM-4.6 Plus"
tags = ["chat", "chinese", "coding", "high-quality", "general"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.6-flash"
provider = "glm"
remote_identifier = "GLM-4.6-Flash"
display_name = "GLM-4.6 Flash"
tags = ["chat", "chinese", "fast", "general"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.5"
provider = "glm"
remote_identifier = "GLM-4.5"
display_name = "GLM-4.5"
tags = ["chat", "chinese", "general", "high-quality"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.5-x"
provider = "glm"
remote_identifier = "GLM-4.5-X"
display_name = "GLM-4.5-X"
tags = ["chat", "chinese", "general", "fast", "high-quality"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.5-air"
provider = "glm"
remote_identifier = "GLM-4.5-Air"
display_name = "GLM-4.5 Air"
tags = ["chat", "chinese", "general", "fast", "cheap"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.5-airx"
provider = "glm"
remote_identifier = "GLM-4.5-AirX"
display_name = "GLM-4.5 AirX"
tags = ["chat", "chinese", "general", "fast"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "glm-4.5-flash"
provider = "glm"
remote_identifier = "GLM-4.5-Flash"
display_name = "GLM-4.5 Flash"
tags = ["chat", "chinese", "general", "fast", "free"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]


###################
# Qwen Models     #
###################

[[models]]
name = "qwen2.5-72b-instruct"
provider = "qwen"
display_name = "Qwen2.5 72B Instruct"
tags = ["chat", "general", "function-call", "high-quality"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "qwen-turbo"
provider = "qwen"
display_name = "Qwen Turbo"
tags = ["chat", "general", "function-call", "fast"]
[models.config]
context_window = "32k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]


###################
# Kimi Models     #
###################

[[models]]
name = "kimi-k2-128k"
provider = "kimi"
display_name = "Kimi K2 128K"
tags = ["chat", "long-context", "summary", "analysis", "high-quality", "function-call"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "kimi-k2-flash"
provider = "kimi"
display_name = "Kimi K2 Flash"
tags = ["chat", "fast", "general", "function-call"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]


######################
# OpenRouter Models  #
######################

[[models]]
name = "llama-3.3-70b-instruct"
provider = "openrouter"
remote_identifier = "meta-llama/llama-3.3-70b-instruct:free"
display_name = "Meta: Llama 3.3.70B Instruct (免费)"
tags = ["chat", "open-source", "free", "general", "high-quality"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "gemma-3-27b-it"
provider = "openrouter"
remote_identifier = "google/gemma-3-27b-it:free"
display_name = "Google: Gemma 3 27B (免费)"
tags = ["chat", "google", "free", "general", "instruction-tuned"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "glm-4.5-air"
provider = "openrouter"
remote_identifier = "z-ai/glm-4.5-air:free"
display_name = "Z.AI: GLM 4.5 Air (免费)"
tags = ["chat", "chinese", "free", "general", "fast"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "mimo-v2-flash"
provider = "openrouter"
remote_identifier = "xiaomi/mimo-v2-flash:free"
display_name = "Xiaomi MIMO V2 Flash (免费)"
tags = ["chat", "general", "function-call", "long-context", "free", "fast", "chinese"]
[models.config]
context_window = "256k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "deepseek-r1t2-chimera"
provider = "openrouter"
remote_identifier = "tngtech/deepseek-r1t2-chimera:free"
display_name = "TNG: DeepSeek R1T2 Chimera (免费)"
tags = ["chat", "general", "reasoning", "function-call", "long-context", "free", "chinese"]
[models.config]
context_window = "160k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "deepseek-v3.1-nex-n1"
provider = "openrouter"
remote_identifier = "nex-agi/deepseek-v3.1-nex-n1:free"
display_name = "Nex AGI: DeepSeek V3.1 Nex N1 (免费)"
tags = ["chat", "general", "function-call", "long-context", "free", "high-quality", "chinese"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "deepseek-r1t-chimera"
provider = "openrouter"
remote_identifier = "tngtech/deepseek-r1t-chimera:free"
display_name = "TNG: DeepSeek R1T Chimera (免费)"
tags = ["chat", "general", "reasoning", "function-call", "long-context", "free", "chinese"]
[models.config]
context_window = "160k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "nemotron-nano-12b-v2-vl"
provider = "openrouter"
remote_identifier = "nvidia/nemotron-nano-12b-v2-vl:free"
display_name = "NVIDIA: Nemotron Nano 12B V2 VL (免费)"
tags = ["chat", "general", "image", "function-call", "long-context", "nvidia", "free"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["en"]

[[models]]
name = "nemotron-3-nano-30b-a58"
provider = "openrouter"
remote_identifier = "nvidia/nemotron-3-nano-30b-a58:free"
display_name = "NVIDIA: Nemotron 3 Nano 30B A58 (免费)"
tags = ["chat", "general", "nvidia", "free", "image", "function-call"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["en"]

[[models]]
name = "tng-r1t-chimera"
provider = "openrouter"
remote_identifier = "tngtech/tng-r1t-chimera:free"
display_name = "TNG R1T Chimera (免费)"
tags = ["chat", "general", "reasoning", "function-call", "long-context", "free"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "olmo-3.1-32b-think"
provider = "openrouter"
remote_identifier = "allenai/olmo-3.1-32b-think:free"
display_name = "AllenAI: Olmo 3.1 32B Think (免费)"
tags = ["chat", "general", "reasoning", "function-call", "free", "open-source"]
[models.config]
context_window = "64k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "molmo-2-8b-4bit"
provider = "openrouter"
remote_identifier = "allenai/molmo-2-8b-4bit:free"
display_name = "AllenAI: Molmo2 8B (免费)"
tags = ["chat", "general", "free", "open-source", "fast"]
[models.config]
context_window = "32k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "qwen3-coder"
provider = "openrouter"
remote_identifier = "qwen/qwen3-coder:free"
display_name = "Qwen: Qwen3 Coder 480B A35B (免费)"
tags = ["coding", "long-context", "qwen", "free", "open-source", "fast", "chinese"]
[models.config]
context_window = "256k"
supports_vision = false
supports_tools = false
languages = ["zh", "en"]

[[models]]
name = "gpt-oss-20b-openrouter"
provider = "openrouter"
remote_identifier = "openai/gpt-oss-20b:free"
display_name = "GPT-OSS 20B (免费)"
tags = ["chat", "general", "function-call", "long-context", "openai", "free", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "deepseek-r1-0528"
provider = "openrouter"
remote_identifier = "deepseek/deepseek-r1-0528:free"
display_name = "DeepSeek R1 0528 (免费)"
tags = ["chat", "general", "reasoning", "function-call", "long-context", "free", "chinese"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "tongyi-deepresearch-30b-a3b"
provider = "openrouter"
remote_identifier = "alibaba/tongyi-deepresearch-30b-a3b:free"
display_name = "Alibaba Tongyi DeepResearch 30B A3B (免费)"
tags = ["chat", "general", "analysis", "research", "function-call", "long-context", "chinese", "free", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]

[[models]]
name = "trinity-mini"
provider = "openrouter"
remote_identifier = "arcee-ai/trinity-mini:free"
display_name = "Arcee AI Trinity Mini (免费)"
tags = ["chat", "general", "function-call", "long-context", "free", "fast"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "dolphin-mistral-24b-venice"
provider = "openrouter"
remote_identifier = "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
display_name = "Venice: Uncensored (免费)"
tags = ["chat", "general", "function-call", "mistral", "free", "open-source"]
[models.config]
context_window = "32k"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "gemini-2.0-flash-exp"
provider = "openrouter"
remote_identifier = "google/gemini-2.0-flash-exp:free"
display_name = "Google: Gemini 2.0 Flash Experimental (免费)"
tags = ["chat", "general", "function-call", "long-context", "gemini", "google", "fast"]
[models.config]
context_window = "1M"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "gemini-3-flash-preview"
provider = "openrouter"
remote_identifier = "google/gemini-3-flash-preview"
display_name = "Google: Gemini 3 Flash Preview"
tags = ["chat", "general", "gemini", "google", "fast", "preview"]
[models.config]
context_window = "1M"
supports_vision = true
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0005          # 每 1k 输入 token 的费用 (USD)
cost_per_1k_completion_tokens = 0.003 # 每 1k 输出 token 的费用 (USD)

[[models]]
name = "gemini-3-pro-preview"
provider = "openrouter"
remote_identifier = "google/gemini-3-pro-preview"
display_name = "Google: Gemini 3 Pro Preview"
tags = ["chat", "general", "gemini", "google", "high-quality", "preview"]
[models.config]
context_window = "1M"
supports_vision = true
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.002          # 每 1k 输入 token 的费用 (USD)
cost_per_1k_completion_tokens = 0.012 # 每 1k 输出 token 的费用 (USD)

[[models]]
name = "gemma-3-12b-it"
provider = "openrouter"
remote_identifier = "google/gemma-3-12b-it:free"
display_name = "Gemma 3 12B IT (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "google", "free"]
[models.config]
context_window = "131k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "gemma-3-4b-it"
provider = "openrouter"
remote_identifier = "google/gemma-3-4b-it:free"
display_name = "Gemma 3 4B IT (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "google", "free", "fast"]
[models.config]
context_window = "32k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "gemma-3n-e2b-it"
provider = "openrouter"
remote_identifier = "google/gemma-3n-e2b-it:free"
display_name = "Google: Gemma 3n 2B (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "google", "free", "fast"]
[models.config]
context_window = "8k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "gemma-3n-e4b-it"
provider = "openrouter"
remote_identifier = "google/gemma-3n-e4b-it:free"
display_name = "Gemma 3n 4B IT (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "google", "free", "fast"]
[models.config]
context_window = "8k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "llama-3.1-405b-instruct"
provider = "openrouter"
remote_identifier = "meta-llama/llama-3.1-405b-instruct:free"
display_name = "Llama 3.1 405B Instruct (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "long-context", "free", "high-quality", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "llama-3.2-3b-instruct"
provider = "openrouter"
remote_identifier = "meta-llama/llama-3.2-3b-instruct:free"
display_name = "Llama 3.2 3B Instruct (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "long-context", "free", "fast", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "mistral-7b-instruct"
provider = "openrouter"
remote_identifier = "mistralai/mistral-7b-instruct:free"
display_name = "Mistral: Mistral 7B Instruct (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "mistral", "free", "open-source"]
[models.config]
context_window = "32k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "mistral-small-3.1-24b-instruct"
provider = "openrouter"
remote_identifier = "mistralai/mistral-small-3.1-24b-instruct:free"
display_name = "Mistral Small 3.1 24B Instruct (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "long-context", "mistral", "free", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "devstral-2-2512"
provider = "openrouter"
remote_identifier = "mistralai/devstral-2-2512:free"
display_name = "Mistral: Devstral 2 2512 (免费)"
tags = ["chat", "general", "reasoning", "mistral", "free", "long-context"]
[models.config]
context_window = "1M"
supports_vision = false
supports_tools = true
languages = ["en"]

[[models]]
name = "kimi-k2"
provider = "openrouter"
remote_identifier = "moonshotai/kimi-k2:free"
display_name = "MoonshotAI: Kimi K2 0711 (免费)"
tags = ["chat", "general", "function-call", "kimi", "free", "chinese"]
[models.config]
context_window = "32k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "hermes-3-llama-3.1-405b"
provider = "openrouter"
remote_identifier = "nousresearch/hermes-3-llama-3.1-405b:free"
display_name = "Nous Hermes 3 Llama 3.1 405B (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "long-context", "free", "high-quality", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "nemotron-nano-9b-v2"
provider = "openrouter"
remote_identifier = "nvidia/nemotron-nano-9b-v2:free"
display_name = "NVIDIA Nemotron Nano 9B V2 (免费)"
tags = ["chat", "general", "function-call", "long-context", "nvidia", "free", "fast"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "gpt-oss-120b"
provider = "openrouter"
remote_identifier = "openai/gpt-oss-120b:free"
display_name = "GPT-OSS 120B (免费)"
tags = ["chat", "general", "function-call", "long-context", "openai", "free", "high-quality", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = true
languages = ["en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "qwen-2.5-vl-7b-instruct"
provider = "openrouter"
remote_identifier = "qwen/qwen-2.5-vl-7b-instruct:free"
display_name = "Qwen 2.5 VL 7B Instruct (免费)"
tags = ["chat", "general", "instruction-tuned", "image", "function-call", "qwen", "free", "chinese"]
[models.config]
context_window = "32k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "qwen3-4b"
provider = "openrouter"
remote_identifier = "qwen/qwen3-4b:free"
display_name = "Qwen3 4B (免费)"
tags = ["chat", "general", "function-call", "qwen", "free", "fast", "chinese"]
[models.config]
context_window = "40k"
supports_vision = false
supports_tools = true
languages = ["zh", "en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0

[[models]]
name = "qwen3-next-80b-a3b-instruct"
provider = "openrouter"
remote_identifier = "qwen/qwen3-next-80b-a3b-instruct:free"
display_name = "Qwen: Qwen3 Next 80B A3B Instruct (免费)"
tags = ["chat", "general", "instruction-tuned", "function-call", "free", "long-context", "qwen"]
[models.config]
context_window = "128k"
supports_vision = true
supports_tools = true
languages = ["zh", "en"]
cost_per_1k_tokens = 0.0
cost_per_1k_completion_tokens = 0.0


######################
# Ollama Models      #
######################

[[models]]
name = "gpt-oss-20b"
provider = "ollama"
remote_identifier = "gpt-oss:20b"
display_name = "GPT-OSS 20B (Ollama)"
tags = ["chat", "local", "ollama", "open-source"]
[models.config]
context_window = "128k"
supports_vision = false
supports_tools = false
languages = ["en"]


######################
# Vercel Models      #
######################

[[models]]
name = "gemini-2.5-flash"
provider = "vercel"
remote_identifier = "gemini-2.5-flash"
display_name = "Gemini 2.5 Flash (Vercel)"
tags = ["chat", "general", "reasoning", "fast", "gemini"]
[models.config]
context_window = "1M"
supports_vision = true
supports_tools = true
languages = ["en"]


######################
# API Key Settings   #
######################
# API Key 配置用于控制对 LLM Router API 的访问
# 认证功能默认开启，所有端点（除 /health）都需要提供有效的 API Key
#
# 重要：API Key 的具体值应该定义在 .env 文件中，而不是直接写在配置文件中
# 这样可以避免将敏感信息提交到版本控制系统

# # 示例1: 无限制的管理员 API Key（从环境变量读取，支持多个 key，逗号分隔）
# [[api_keys]]
# key_env = "LLM_ROUTER_ADMIN_KEY"  # 从 .env 文件中的环境变量读取，支持多个 key（如：key1,key2,key3）
# name = "管理员密钥"
# is_active = true
# # allowed_models = null  # null 表示无限制
# # allowed_providers = null  # null 表示无限制
# # parameter_limits = null  # null 表示无参数限制

# # 示例2: 限制只能调用特定模型的 API Key
# [[api_keys]]
# key_env = "LLM_ROUTER_LIMITED_KEY"
# name = "受限密钥 - 仅 GPT 模型"
# is_active = true
# allowed_models = [
#     "openai/gpt-5.1",
#     "openai/gpt-5-pro",
# ]
# # allowed_providers = ["openai"]  # 也可以限制 Provider
# [api_keys.parameter_limits]
# max_tokens = 1000
# temperature = 1.0

# # 示例3: 限制参数的高级 API Key
# [[api_keys]]
# key_env = "LLM_ROUTER_RESTRICTED_KEY"
# name = "受限参数密钥"
# is_active = true
# allowed_models = [
#     "openai/gpt-5.1",
#     "claude/claude-4.5-sonnet",
# ]
# [api_keys.parameter_limits]
# max_tokens = 2000
# temperature = 0.7
# top_p = 0.9
# frequency_penalty = 0.0
# presence_penalty = 0.0
# # 自定义参数限制
# [api_keys.parameter_limits.custom_limits]
# custom_param = 100

# # 示例4: 仅允许特定 Provider 的 API Key
# [[api_keys]]
# key_env = "LLM_ROUTER_OPENROUTER_KEY"
# name = "仅 OpenRouter 密钥"
# is_active = true
# allowed_providers = ["openrouter"]
# # 允许所有 OpenRouter 的模型，但限制参数
# [api_keys.parameter_limits]
# max_tokens = 500
# temperature = 0.5

# # 示例5: 禁用的 API Key
# [[api_keys]]
# key_env = "LLM_ROUTER_DISABLED_KEY"
# name = "已禁用密钥"
# is_active = false

# # 注意：也可以直接使用 key 字段（不推荐，仅用于测试）
# # [[api_keys]]
# # key = "test-key-direct"  # 直接指定 key（不推荐用于生产环境）
# # name = "测试密钥"
# # is_active = true

